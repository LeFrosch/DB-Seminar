\documentclass[acmlarge,nonacm]{acmart}

% For images 
\usepackage{graphicx}
\usepackage{wrapfig}

\graphicspath{ {./images/} }

\begin{document}
    \title{Concurrent online sampling, for all, for free}

    \author{Daniel Brauner}
    \email{daniel.brauner@tum.de}
    
    \begin{abstract}
        This is the abstract.
    \end{abstract}

    % From the OG
    \keywords{online sampling, database statistics, query optimization}

    \maketitle

    \section{Introduction}
        % What is sampling
        A random subset of data is called a sample, usually the sample is much smaller then the actual date. In the context of Database Management Systems (DBMS) a sample is a smaller table that contains a copy of random rows from a table. The process of creating and maintaining a sample is called sampling. Maintaining hereby refers to keeping the sample up to date when the underlying data changes.
    
        % Why is sampling necessary
        Such a sample can be used by the query optimizer in modern DBMS. For instance the date stored in the sample can be used to predict the size of intermediate results when joining multiple tables. This is very important when the query optimizer tries to determine the order in which the joins should be executed. Also, the sample can be used to predict the result of aggregate queries, like SUM, COUNT, etc. 


    \section{Motivation} 
        % Current sampling algorithms
        The most naive way to provide a sample to the optimizer, would be generating it on demand. But generating a sample is not cheap, specially when the data is stored on disk. Because to create a random sample, random rows need to be read resulting in random I/O. Therefore, in some cases generating the sample can take more time then the actual query to execute.

        Some modern DBMS address this problem by only generating the sample periodically. Generating the sample still requires random I/O but the coast can be amortized over multiple queries. However, this introduces a new issues, the sample can become stale over time. Hence, predictions based on the sample can be wrong and are no longer useful for the query optimizer.

    \section{Solution}
        % What is online sampling
        Online sampling tries to address these issues by keeping the sample up to date while inserting new tuples into the Database. Because every tuple that is going to be inserted is taken into consideration by the algorithm the sample is always up to date. Furthermore, no random I/O is required because no rows need to be retrieved from the disk. Modern DBMS use multiple threads for inserting therefore the algorithm also needs to support multithreading with very little overhead.
        % Requirements
        In consequence the requirements are:
        \begin{enumerate}
            \item Keep Samples up to date while inserting new tuples
            \item As little overhead as possible, per thread and overall
            \item Use constant amount of memory
            \item Easy integration into existing solutions
            \item Minimum amount of shared memory writes (as less locks as possible)
        \end{enumerate}
        
    \subsection{The skip node}
        % The idea behind skip length
        For every tuple that is inserted into the database the algorithm needs to determine whether the tuple should also be added to the sample or not. The tuples which are not inserted are "skipped" and tuples which are inserted into the sample are called reservoir tuples. Because the sampling strategy used by this algorithm is based on reservoir sampling [source], herby incoming tuples are inserted into the reservoir with some probability. 
        
        \begin{wrapfigure}{r}{0.4\textwidth}
            \centering
            \includegraphics[height=5cm]{figure1.pdf}
            \caption{Example of two Skips with different lengths}
        \end{wrapfigure}
        But deciding for every tuple separately using the probability method can be rather expensive. Therefore, the algorithm generates a length instead. The length and some additional metadata is called a Skip and can be stored in a node. A Skip can be used to determine how many tuples should be skipped until the next reservoir tuple. Determining whether a tuple is a reservoir tuple or not using the length of a Skip is very cheap. First the length needs to be decremented by one and if the length reached zero the current tuple is a reservoir tuple and a new Skip needs to be generated. If the length remains greater then zero the current tuple should be skipped. Figure one shows an example for two Skips. The white tuples are skipped and the gray tuples are reservoir tuples.

        % Multithreaded nodes
        Hence, Skips are already stored in self contained nodes, these nodes can easily be distributed among multiple threads. Only the generation and distribution needs to be synchronized. After a thread received a Skip it takes ownership of it, therefore the thread has exclusive access to it until the Skip is returned. Once a thread owns a Skip no more synchronization is required and the thread can work independently. 

        % Preallocation
        To ensure the constant use of memory it is necessary that the maximum amount of threads that can be used for inserting is known when the algorithm is initialized. In consequence, all nodes can be preallocated, one for every thread and one additional node as reserve. Hence, a pointer to a node can simply be an index into the node array.

        % States of a skip node
        \begin{figure}[h]
            \includegraphics[height=3.5cm]{figure2.pdf}
            \caption{States of a node and the transitions between the states}
        \end{figure}
        One additional field that is stored in every node, is a successor pointer. This pointer can be used to arrange nodes in a singly linked list. There are three states a node can be in, initially all nodes are in the free list. The free list contains all nodes that are currently not owned by any thread and nodes that do not contain a Skip. If a Skip should be generated a node needs to be allocated, thus it needs to be removed from the free list and the data of the Skip can be stored in this node. Afterwards, the node is added to the list of skips (LOS). The LOS contains all nodes that store a valid Skip, but are not currently owned by a thread. Additionally the LOS should always contain at least on Skip. When a thread needs acquire a new Skip, it can pop the first item of the LOS. Afterwards, the thread might need to generate a new Skip to ensure that the LOS is not empty. Figure two illustrates the lifecycle of a node.

    \subsection{Sampling while inserting}

        % Description of the process
        Every thread receives an independent stream of tuples that should be inserted and therefore also sampled. The amount of tuples is unknown and each thread could stop receiving tuples at any moment. To determine if a tuple is reservoir tuple or not the thread needs to own a Skip. Therefore, if the thread currently does not own a valid Skip it needs to acquire a new one. A Skip can be invalid if the length already is zero. Once the thread owns a Skip it can use the the length to determine whether the tuple is a reservoir tuple using the process described above. If the tuple is a reservoir tuple it needs to be inserted into the sample, but in both cases the tuple needs to be inserted into the database. Figure three shows a flow diagram for this process with two key decision points. 

        \begin{figure}[h]
            \includegraphics[height=2.9cm]{figure3.pdf}
            \caption{Flow diagram that shows the steps necessary to determine whether a tuple is a reservoir tuple}
        \end{figure}

        % Synchronization 
        This process only introduces two cases in which extra synchronization is required. First, if a new Skip needs to be acquire and second if the tuple needs to be added to sample. However, both of theses cases only apply when the length reached zero and when inserting into the sample most of the time the different threads do not interfere with each other.

    \subsection{Inserting into the sample}

        % Description of the Sample table
        Besides the actual tuples the sample contains on additional filed.

    \section{Example}
        % An example who the algorithm works (similar to one in the OG)
        This is an example.

    \section{Evaluation}
        % Are all requirements met
        % Tables from the OG
        This is the evaluation.

\end{document}